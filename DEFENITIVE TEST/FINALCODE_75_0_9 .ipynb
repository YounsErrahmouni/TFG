{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persones=pd.read_csv('Accident_people_2021_2022.csv')\n",
    "persones.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather=pd.read_csv('data_meteo_estudifinal_2021_2022.csv')\n",
    "weather = weather.drop(weather.columns[0], axis=1)\n",
    "weather.rename(columns={'DATA_LECTURA':'Date'},inplace=True)\n",
    "weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persones= persones[persones['Person_type'] == 'Driver']\n",
    "persones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FROM ALL THE DATA WE ARE JUST GOING TO FOCUS NÂ¡ON THE DRIVERS BECAUSE\n",
    "#THE PASSANGER OR THE PEDESTRIAN DOESN0T HAVE ANY KIND OF POWER TO NOT BE IN THE SITUATION OR HAVE ANY CONTROL\n",
    "\n",
    "persones=persones[['Day_shift','Vehicle_type','Gender','Age','Date']]\n",
    "weather=weather[['Date','03.TM','06.HRM','10.VVM10']]\n",
    "\n",
    "#JOIN THE DATASETS WITH THE VARIABLE DATE\n",
    "variables = pd.merge(persones, weather, on='Date', how='left')\n",
    "variables.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add variable quarter and start studying the different variables\n",
    "variables['Quarter'] = variables['Date'].apply(lambda x: pd.Timestamp(x).quarter)\n",
    "variables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LETS TRANSFORM TO CATHEGORIC THE COLUMN EDAT\n",
    "#/// desconegut(404) -->NOT KNOWN\n",
    "#transform value desconegut a 404\n",
    "variables['Age'] = variables['Age'].replace('Desconegut', '404')\n",
    "def categorize_age(age):\n",
    "    if int(age) <= 25:\n",
    "        return '16-25'\n",
    "    elif int(age) <= 35 and int(age) > 25:\n",
    "        return '26-35'\n",
    "    elif int(age) <= 45 and int(age) > 35:\n",
    "        return '36-45'\n",
    "    elif int(age) <= 55 and int(age) > 45:\n",
    "        return '46-55'\n",
    "    elif age == '404':\n",
    "        return 'Age not known'\n",
    "    else:\n",
    "        return '+56'\n",
    "\n",
    "# Apply function to transform ages to categories\n",
    "variables['Age'] = variables['Age'].apply(categorize_age)\n",
    "\n",
    "x=variables['Age'].unique()\n",
    "print(x)\n",
    "\n",
    "# count the frequency of each value in column 'a'\n",
    "value_counts = variables['Age'].value_counts()\n",
    "\n",
    "# calculate the percentage of times each value appears\n",
    "percentage = (value_counts / len(variables)) * 100\n",
    "print(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=variables['03.TM'].unique()\n",
    "# print(np.sort(x)) the data goes from 3.8 to 34.2\n",
    "def cat_temp(temp):\n",
    "    if int(temp) <= 13:\n",
    "        return 'Very low'\n",
    "    elif int(temp) <= 17 and int(temp) > 13:\n",
    "        return 'Low'\n",
    "    elif int(temp) <= 24 and int(temp) > 17:\n",
    "        return 'Mild'\n",
    "    else:\n",
    "        return 'Hot'\n",
    "variables['03.TM'] = variables['03.TM'].apply(cat_temp)\n",
    "\n",
    "x=variables['03.TM'].unique()\n",
    "print(x)\n",
    "\n",
    "# count the frequency of each value in column 'a'\n",
    "value_counts = variables['03.TM'].value_counts()\n",
    "\n",
    "# calculate the percentage of times each value appears\n",
    "percentage = (value_counts / len(variables)) * 100\n",
    "print(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=variables['06.HRM'].unique()\n",
    "#print(np.sort(x)) from 9 percent to 100 percent\n",
    "def cat_humidity(hum):\n",
    "    if int(hum) <= 48:\n",
    "        return 'Low humidity'\n",
    "    elif int(hum) <= 60 and int(hum) > 48:\n",
    "        return 'Moderate humidity'\n",
    "    elif int(hum) <= 75 and int(hum) > 60:\n",
    "        return 'High humidity'\n",
    "    else:\n",
    "        return 'Very high'\n",
    "variables['06.HRM'] = variables['06.HRM'].apply(cat_humidity)\n",
    "\n",
    "x=variables['06.HRM'].unique()\n",
    "print(x)\n",
    "\n",
    "# count the frequency of each value in column 'a'\n",
    "value_counts = variables['06.HRM'].value_counts()\n",
    "\n",
    "# calculate the percentage of times each value appears\n",
    "percentage = (value_counts / len(variables)) * 100\n",
    "print(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=variables['10.VVM10'].unique()\n",
    "#print(np.sort(x)) from 0 to 8.7\n",
    "def cat_wind(wind):\n",
    "    if int(wind) <= 1:\n",
    "        return 'Low speed'\n",
    "    elif int(wind) <= 2 and int(wind) > 1:\n",
    "        return 'Moderate speed'\n",
    "    else:\n",
    "        return 'High speed'\n",
    "    \n",
    "variables['10.VVM10'] = variables['10.VVM10'].apply(cat_wind)\n",
    "\n",
    "x=variables['10.VVM10'].unique()\n",
    "print(x)\n",
    "\n",
    "# count the frequency of each value in column 'a'\n",
    "value_counts = variables['10.VVM10'].value_counts()\n",
    "\n",
    "# calculate the percentage of times each value appears\n",
    "percentage = (value_counts / len(variables)) * 100\n",
    "print(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from sklearn import preprocessing\n",
    "from kmodes.kmodes import KModes\n",
    "# List of variable names\n",
    "variables_name = ['Day_shift', 'Vehicle_type', 'Gender', 'Age', '03.TM', '06.HRM', '10.VVM10', 'Quarter']\n",
    "\n",
    "# Generate combinations of 4 to 8 variables\n",
    "combinations_list = []\n",
    "for r in range(4, 9):\n",
    "    combinations_list.extend(combinations(variables_name, r))\n",
    "\n",
    "# Empty DataFrame to store results\n",
    "table = pd.DataFrame()\n",
    "\n",
    "def tuple_to_list(t):\n",
    "    new_list = []\n",
    "    for element in t:\n",
    "        new_list.append(element)\n",
    "    return new_list\n",
    "\n",
    "# Iterate over combinations\n",
    "for selected_columns in combinations_list:\n",
    "    # Select columns from 'variables' DataFrame based on the combination\n",
    "    listavar = tuple_to_list(selected_columns)\n",
    "    subgrup_1 = variables[listavar]\n",
    "    print(subgrup_1.shape[1])\n",
    "    # Clustering code\n",
    "    subgroup = subgrup_1.copy()\n",
    "    from sklearn import preprocessing  \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    subgroup_encoded = subgroup.apply(le.fit_transform)\n",
    "    #to create the list to get the percenge of significant clusters\n",
    "    l=[]\n",
    "    # Iterate through cluster numbers\n",
    "    for n_clusters in range(3, 19):\n",
    "        # Clustering\n",
    "        km = KModes(n_clusters=n_clusters, init='Cao', n_init=1, verbose=1)\n",
    "        clusters = km.fit_predict(subgroup_encoded)\n",
    "\n",
    "        # Combine with original data\n",
    "        combined = pd.concat([subgroup.reset_index(), pd.DataFrame({'Cluster': clusters})], axis=1).drop('index', axis=1)\n",
    "\n",
    "        # Create table\n",
    "        table = pd.DataFrame(columns=range(n_clusters))\n",
    "\n",
    "        # Fill in table with percentage of instances of each value in each cluster for each variable\n",
    "        for var in subgroup.columns:\n",
    "            by_cluster_value = combined.groupby(['Cluster', var]).size()\n",
    "            percentages = by_cluster_value.groupby(level=0).apply(lambda x: x / x.sum() * 100)\n",
    "            pivot_table = pd.pivot_table(percentages.reset_index(), index=var, columns='Cluster', values=0, fill_value=0)\n",
    "\n",
    "            # Fill in table with percentage of instances for each value in each cluster\n",
    "            for i, col in enumerate(pivot_table.columns):\n",
    "                values = pivot_table[col].index.tolist()\n",
    "                pct_values = pivot_table[col].tolist()\n",
    "                for j, value in enumerate(values):\n",
    "                    table.loc[value, i] = pct_values[j]\n",
    "            # Add new column with variable names based on index\n",
    "        table['VARIABLE'] = ''\n",
    "\n",
    "        variable_mapping = {}\n",
    "\n",
    "        for column in subgroup.columns:\n",
    "            unique_values = subgroup[column].unique()\n",
    "            variable_mapping[column] = unique_values\n",
    "\n",
    "        for i, index_value in enumerate(table.index.values):\n",
    "            for variable, values in variable_mapping.items():\n",
    "                if index_value in values:\n",
    "                    table.iloc[i, -1] = variable\n",
    "                    break\n",
    "        print(table)\n",
    "        table = table.reset_index().rename(columns={'index': 'value'})\n",
    "        table = table[['VARIABLE'] + list(table.columns[:-1])]\n",
    "        #print(table)\n",
    "        table = table.set_index('VARIABLE')       \n",
    "\n",
    "        # Add a new row for the cluster drivers percentage\n",
    "        table.loc['Cluster percentage of drivers'] = 0\n",
    "\n",
    "        # Calculate the number of instances in each cluster\n",
    "        cluster_counts = combined['Cluster'].value_counts()\n",
    "\n",
    "        # Fill in the table with the percentage of instances in each cluster\n",
    "        for i, count in cluster_counts.items():\n",
    "            table.loc['Cluster percentage of drivers', i] = count / len(combined) * 100\n",
    "    \n",
    "        #table.to_excel(f'table_{n_clusters}_clusters_pas1.xlsx', index=True)\n",
    "        table1=table\n",
    "        # Save table to CSV file\n",
    "        table = table.drop('value', axis=1)\n",
    "        new_table_2 = pd.DataFrame(index=table.index.unique())\n",
    "    # Iterate over each column (0, 1, 2, 3) and find the highest percentage for each variable\n",
    "        for col in table.columns:\n",
    "            col_max = table.groupby(level=0)[col].max()\n",
    "            new_table_2[col] = col_max\n",
    "    # Add the 'Cluster percentage of drivers' row back to the new DataFrame\n",
    "        new_table_2.loc['Cluster percentage of drivers'] = table.loc['Cluster percentage of drivers']\n",
    "    # Display the new DataFrame\n",
    "        #print(new_table_2)\n",
    "        #new_table_2.to_excel(f'table_{n_clusters}_clusters_pas2.xlsx', index=True)\n",
    "        new_table_3= new_table_2.loc[new_table_2.index != 'Cluster percentage of drivers'] = (new_table_2.loc[new_table_2.index != 'Cluster percentage of drivers'] >= 75).astype(int)\n",
    "        new_table_3.loc['VARIABLES => 75%'] = new_table_3.sum()\n",
    "        #new_table_2.to_excel(f'table_{n_clusters}_clusters_pas3.xlsx', index=True)\n",
    "        #print(new_table_3)\n",
    "        print(subgrup_1.shape[1])  \n",
    "        new_table_3.loc['Cluster Value'] = new_table_3 .loc['VARIABLES => 75%'] / subgrup_1.shape[1]\n",
    "        new_table_3.loc['Cluster adequate?'] = new_table_3 .loc['Cluster Value']>0.5\n",
    "        new_table_4=new_table_3\n",
    "        new_table_4.loc['Cluster percentage of drivers'] = table.loc['Cluster percentage of drivers']\n",
    "        new_table_4.loc['SCORE'] = np.nan\n",
    "        new_table_4.loc['SCORE' ,'TOTAL CLUSTERIZATION VALUE'] = new_table_4.loc['Cluster adequate?'].sum() / n_clusters\n",
    "        if new_table_4.loc['Cluster adequate?'].sum() / n_clusters > 0.9:\n",
    "            table1.to_excel(f'table_{n_clusters}_clusters_{\"\".join(selected_columns)}.xlsx', index=True)\n",
    "       \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qda-environment_MAC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ddbab500cb11211a745680fd9d1a021ebe387ff4c58205a0c57203e83576c9f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
