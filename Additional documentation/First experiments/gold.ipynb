{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from kmodes.kmodes import KModes\n",
    "\n",
    "# Subset of variables for clustering\n",
    "subgroup = variables[['Day_shift', 'Vehicle_type', 'Gender', 'Age', '03.TM']]\n",
    "\n",
    "# Label encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "subgroup_encoded = subgroup.apply(le.fit_transform)\n",
    "\n",
    "# Iterate through cluster numbers\n",
    "for n_clusters in range(5, 11):\n",
    "    # Clustering\n",
    "    km = KModes(n_clusters=n_clusters, init='Cao', n_init=1, verbose=1)\n",
    "    clusters = km.fit_predict(subgroup_encoded)\n",
    "\n",
    "    # Combine with original data\n",
    "    combined = pd.concat([subgroup.reset_index(), pd.DataFrame({'Cluster': clusters})], axis=1).drop('index', axis=1)\n",
    "\n",
    "    # Number and percentage of drivers in each cluster\n",
    "    n_drivers = combined['Cluster'].value_counts().sort_index()\n",
    "    pct_drivers = n_drivers / n_drivers.sum() * 100\n",
    "\n",
    "    # Create table\n",
    "    table = pd.DataFrame(index=['Number of drivers', 'Percentage of drivers'])\n",
    "\n",
    "    # Fill in first row of table with number of drivers\n",
    "    for i in range(n_clusters):\n",
    "        table[i] = [n_drivers[i], pct_drivers[i]]\n",
    "\n",
    "    # Add blank row\n",
    "    table.loc[''] = ''\n",
    "\n",
    "    # Fill in table with percentage of instances of each value in each cluster for each variable\n",
    "    for var in subgroup.columns:\n",
    "        by_cluster_value = combined.groupby(['Cluster', var]).size()\n",
    "        percentages = by_cluster_value.groupby(level=0).apply(lambda x: x / x.sum() * 100)\n",
    "        pivot_table = pd.pivot_table(percentages.reset_index(), index=var, columns='Cluster', values=0, fill_value=0)\n",
    "\n",
    "        # Add variable name to table\n",
    "        table.loc[var] = ''\n",
    "\n",
    "        # Fill in table with percentage of instances for each value in each cluster\n",
    "        for i, col in enumerate(pivot_table.columns):\n",
    "            values = pivot_table[col].index.tolist()\n",
    "            pct_values = pivot_table[col].tolist()\n",
    "            table.loc[var, i] = col\n",
    "            for j, value in enumerate(values):\n",
    "                table.loc[value, i] = pct_values[j]\n",
    "\n",
    "    # Save table to CSV file\n",
    "    table.to_excel(f'table_{n_clusters}_clusters.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from kmodes.kmodes import KModes\n",
    "\n",
    "# Subset of variables for clustering\n",
    "subgroup = variables[['Day_shift', 'Vehicle_type', 'Gender', 'Age', '03.TM']]\n",
    "\n",
    "# Label encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "subgroup_encoded = subgroup.apply(le.fit_transform)\n",
    "\n",
    "# Iterate through cluster numbers\n",
    "for n_clusters in range(3, 5):\n",
    "    # Clustering\n",
    "    km = KModes(n_clusters=n_clusters, init='Cao', n_init=1, verbose=1)\n",
    "    clusters = km.fit_predict(subgroup_encoded)\n",
    "\n",
    "    # Combine with original data\n",
    "    combined = pd.concat([subgroup.reset_index(), pd.DataFrame({'Cluster': clusters})], axis=1).drop('index', axis=1)\n",
    "\n",
    "    # Create table\n",
    "    table = pd.DataFrame(columns=range(n_clusters))\n",
    "\n",
    "    # Fill in table with percentage of instances of each value in each cluster for each variable\n",
    "    for var in subgroup.columns:\n",
    "        by_cluster_value = combined.groupby(['Cluster', var]).size()\n",
    "        percentages = by_cluster_value.groupby(level=0).apply(lambda x: x / x.sum() * 100)\n",
    "        pivot_table = pd.pivot_table(percentages.reset_index(), index=var, columns='Cluster', values=0, fill_value=0)\n",
    "\n",
    "        # Fill in table with percentage of instances for each value in each cluster\n",
    "        for i, col in enumerate(pivot_table.columns):\n",
    "            values = pivot_table[col].index.tolist()\n",
    "            pct_values = pivot_table[col].tolist()\n",
    "            for j, value in enumerate(values):\n",
    "                table.loc[value, i] = pct_values[j]\n",
    "        # Add new column with variable names based on index\n",
    "    table['VARIABLE'] = ''\n",
    "    for i, index_value in enumerate(table.index.values):\n",
    "        if index_value in ['Afternoon', 'Morning', 'Night']:\n",
    "            table.iloc[i, -1] = 'Day_shift'\n",
    "        elif index_value in subgroup['Vehicle_type'].unique():\n",
    "            table.iloc[i, -1] = 'Vehicle_type'\n",
    "        elif index_value in subgroup['Gender'].unique():\n",
    "            table.iloc[i, -1] = 'Gender'\n",
    "        elif index_value in subgroup['Age'].unique():\n",
    "            table.iloc[i, -1] = 'Age'\n",
    "        else:\n",
    "            table.iloc[i, -1] = '03.TM'\n",
    "    table = table.reset_index().rename(columns={'index': 'value'})\n",
    "    table = table[['VARIABLE'] + list(table.columns[:-1])]\n",
    "    table = table.set_index('VARIABLE')        \n",
    "\n",
    "    # Add a new row for the cluster totals\n",
    "    table.loc['Cluster percentage of drivers'] = 0\n",
    "\n",
    "    # Calculate the number of instances in each cluster\n",
    "    cluster_counts = combined['Cluster'].value_counts()\n",
    "\n",
    "    # Fill in the table with the percentage of instances in each cluster\n",
    "    for i, count in cluster_counts.items():\n",
    "        table.loc['Cluster percentage of drivers', i] = count / len(combined) * 100\n",
    "\n",
    "    # Save table to CSV file\n",
    "    #table.to_excel(f'table_{n_clusters}_clusters.xlsx', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from kmodes.kmodes import KModes\n",
    "\n",
    "# Subset of variables for clustering\n",
    "subgroup = variables[['Day_shift', 'Vehicle_type', 'Gender', 'Age', '03.TM']]\n",
    "\n",
    "# Label encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "subgroup_encoded = subgroup.apply(le.fit_transform)\n",
    "\n",
    "# Iterate through cluster numbers\n",
    "for n_clusters in range(3, 6):\n",
    "    # Clustering\n",
    "    km = KModes(n_clusters=n_clusters, init='Cao', n_init=1, verbose=1)\n",
    "    clusters = km.fit_predict(subgroup_encoded)\n",
    "\n",
    "    # Combine with original data\n",
    "    combined = pd.concat([subgroup.reset_index(), pd.DataFrame({'Cluster': clusters})], axis=1).drop('index', axis=1)\n",
    "\n",
    "    # Create table\n",
    "    table = pd.DataFrame(columns=range(n_clusters))\n",
    "\n",
    "    # Fill in table with percentage of instances of each value in each cluster for each variable\n",
    "    for var in subgroup.columns:\n",
    "        by_cluster_value = combined.groupby(['Cluster', var]).size()\n",
    "        percentages = by_cluster_value.groupby(level=0).apply(lambda x: x / x.sum() * 100)\n",
    "        pivot_table = pd.pivot_table(percentages.reset_index(), index=var, columns='Cluster', values=0, fill_value=0)\n",
    "\n",
    "        # Fill in table with percentage of instances for each value in each cluster\n",
    "        for i, col in enumerate(pivot_table.columns):\n",
    "            values = pivot_table[col].index.tolist()\n",
    "            pct_values = pivot_table[col].tolist()\n",
    "            for j, value in enumerate(values):\n",
    "                table.loc[value, i] = pct_values[j]\n",
    "        # Add new column with variable names based on index\n",
    "    table['VARIABLE'] = ''\n",
    "    for i, index_value in enumerate(table.index.values):\n",
    "        if index_value in ['Afternoon', 'Morning', 'Night']:\n",
    "            table.iloc[i, -1] = 'Day_shift'\n",
    "        elif index_value in subgroup['Vehicle_type'].unique():\n",
    "            table.iloc[i, -1] = 'Vehicle_type'\n",
    "        elif index_value in subgroup['Gender'].unique():\n",
    "            table.iloc[i, -1] = 'Gender'\n",
    "        elif index_value in subgroup['Age'].unique():\n",
    "            table.iloc[i, -1] = 'Age'\n",
    "        else:\n",
    "            table.iloc[i, -1] = '03.TM'\n",
    "    table = table.reset_index().rename(columns={'index': 'value'})\n",
    "    table = table[['VARIABLE'] + list(table.columns[:-1])]\n",
    "    table = table.set_index('VARIABLE')        \n",
    "\n",
    "    # Add a new row for the cluster totals\n",
    "    table.loc['Cluster percentage of drivers'] = 0\n",
    "\n",
    "    # Calculate the number of instances in each cluster\n",
    "    cluster_counts = combined['Cluster'].value_counts()\n",
    "\n",
    "    # Fill in the table with the percentage of instances in each cluster\n",
    "    for i, count in cluster_counts.items():\n",
    "        table.loc['Cluster percentage of drivers', i] = count / len(combined) * 100\n",
    "   \n",
    "    table.to_excel(f'table_{n_clusters}_clusters_pas1.xlsx', index=True)\n",
    "\n",
    "    # Save table to CSV file\n",
    "    table = table.drop('value', axis=1)\n",
    "    new_table_2 = pd.DataFrame(index=table.index.unique())\n",
    "# Iterate over each column (0, 1, 2, 3) and find the highest percentage for each variable\n",
    "    for col in table.columns:\n",
    "        col_max = table.groupby(level=0)[col].max()\n",
    "        new_table_2[col] = col_max\n",
    "# Add the 'Cluster percentage of drivers' row back to the new DataFrame\n",
    "    new_table_2.loc['Cluster percentage of drivers'] = table.loc['Cluster percentage of drivers']\n",
    "# Display the new DataFrame\n",
    "    #print(new_table_2)\n",
    "    new_table_2.to_excel(f'table_{n_clusters}_clusters_pas2.xlsx', index=True)\n",
    "    new_table_3= new_table_2.loc[new_table_2.index != 'Cluster percentage of drivers'] = (new_table_2.loc[new_table_2.index != 'Cluster percentage of drivers'] >= 70).astype(int)\n",
    "    new_table_3.loc['number of significant variables'] = new_table_3.sum()\n",
    "    new_table_2.to_excel(f'table_{n_clusters}_clusters_pas3.xlsx', index=True)\n",
    "    #print(new_table_3)  \n",
    "    new_table_3.loc['Cluster significance'] = new_table_3 .loc['number of significant variables'] / 5\n",
    "    new_table_3.loc['Cluster significant?'] = new_table_3 .loc['Cluster significance']>=0.5\n",
    "    new_table_4=new_table_3\n",
    "    new_table_4.loc['Cluster percentage of drivers'] = table.loc['Cluster percentage of drivers']\n",
    "    new_table_4.loc['Significant clusters'] = np.nan\n",
    "# Add a column with the percentage of significant cluster\n",
    "    new_table_4.loc['Significant clusters' ,'percentage of significant cluster'] = new_table_4.loc['Cluster significant?'].sum() / n_clusters\n",
    "# Transpose the dataframe back to its original orientation\n",
    "# Print the resulting dataframe\n",
    "    new_table_4.to_excel(f'table_{n_clusters}_clusters_pas4.xlsx', index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finalisimocon iteracion variables i clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from sklearn import preprocessing\n",
    "from kmodes.kmodes import KModes\n",
    "# List of variable names\n",
    "variables_name = ['Day_shift', 'Vehicle_type', 'Gender', 'Age', '03.TM', '06.HRM', '10.VVM10', 'Quarter']\n",
    "\n",
    "# Generate combinations of 5 variables\n",
    "comb = combinations(variables_name, 5)\n",
    "\n",
    "# Empty DataFrame to store results\n",
    "table = pd.DataFrame()\n",
    "def tuple_to_list(t):\n",
    "    new_list = []\n",
    "    for element in t:\n",
    "        new_list.append(element)\n",
    "    return new_list\n",
    "\n",
    "# Iterate over combinations\n",
    "for selected_columns in comb:\n",
    "    # Select columns from 'variables' DataFrame based on the combination\n",
    "    listavar=tuple_to_list(selected_columns)\n",
    "    subgrup_1 = variables[listavar]\n",
    "\n",
    "    # Clustering code\n",
    "    subgroup = subgrup_1.copy()\n",
    "    from sklearn import preprocessing  \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    subgroup_encoded = subgroup.apply(le.fit_transform)\n",
    "    #to create the list to get the percenge of significant clusters\n",
    "    l=[]\n",
    "    # Iterate through cluster numbers\n",
    "    for n_clusters in range(3, 5):\n",
    "        # Clustering\n",
    "        km = KModes(n_clusters=n_clusters, init='Cao', n_init=1, verbose=1)\n",
    "        clusters = km.fit_predict(subgroup_encoded)\n",
    "\n",
    "        # Combine with original data\n",
    "        combined = pd.concat([subgroup.reset_index(), pd.DataFrame({'Cluster': clusters})], axis=1).drop('index', axis=1)\n",
    "\n",
    "        # Create table\n",
    "        table = pd.DataFrame(columns=range(n_clusters))\n",
    "\n",
    "        # Fill in table with percentage of instances of each value in each cluster for each variable\n",
    "        for var in subgroup.columns:\n",
    "            by_cluster_value = combined.groupby(['Cluster', var]).size()\n",
    "            percentages = by_cluster_value.groupby(level=0).apply(lambda x: x / x.sum() * 100)\n",
    "            pivot_table = pd.pivot_table(percentages.reset_index(), index=var, columns='Cluster', values=0, fill_value=0)\n",
    "\n",
    "            # Fill in table with percentage of instances for each value in each cluster\n",
    "            for i, col in enumerate(pivot_table.columns):\n",
    "                values = pivot_table[col].index.tolist()\n",
    "                pct_values = pivot_table[col].tolist()\n",
    "                for j, value in enumerate(values):\n",
    "                    table.loc[value, i] = pct_values[j]\n",
    "            # Add new column with variable names based on index\n",
    "        table['VARIABLE'] = ''\n",
    "\n",
    "        variable_mapping = {}\n",
    "\n",
    "        for column in subgroup.columns:\n",
    "            unique_values = subgroup[column].unique()\n",
    "            variable_mapping[column] = unique_values\n",
    "\n",
    "        for i, index_value in enumerate(table.index.values):\n",
    "            for variable, values in variable_mapping.items():\n",
    "                if index_value in values:\n",
    "                    table.iloc[i, -1] = variable\n",
    "                    break\n",
    "\n",
    "        table = table.reset_index().rename(columns={'index': 'value'})\n",
    "        table = table[['VARIABLE'] + list(table.columns[:-1])]\n",
    "        table = table.set_index('VARIABLE')       \n",
    "\n",
    "        # Add a new row for the cluster totals\n",
    "        table.loc['Cluster percentage of drivers'] = 0\n",
    "\n",
    "        # Calculate the number of instances in each cluster\n",
    "        cluster_counts = combined['Cluster'].value_counts()\n",
    "\n",
    "        # Fill in the table with the percentage of instances in each cluster\n",
    "        for i, count in cluster_counts.items():\n",
    "            table.loc['Cluster percentage of drivers', i] = count / len(combined) * 100\n",
    "    \n",
    "        #table.to_excel(f'table_{n_clusters}_clusters_pas1.xlsx', index=True)\n",
    "\n",
    "        # Save table to CSV file\n",
    "        table = table.drop('value', axis=1)\n",
    "        new_table_2 = pd.DataFrame(index=table.index.unique())\n",
    "    # Iterate over each column (0, 1, 2, 3) and find the highest percentage for each variable\n",
    "        for col in table.columns:\n",
    "            col_max = table.groupby(level=0)[col].max()\n",
    "            new_table_2[col] = col_max\n",
    "    # Add the 'Cluster percentage of drivers' row back to the new DataFrame\n",
    "        new_table_2.loc['Cluster percentage of drivers'] = table.loc['Cluster percentage of drivers']\n",
    "    # Display the new DataFrame\n",
    "        #print(new_table_2)\n",
    "        #new_table_2.to_excel(f'table_{n_clusters}_clusters_pas2.xlsx', index=True)\n",
    "        new_table_3= new_table_2.loc[new_table_2.index != 'Cluster percentage of drivers'] = (new_table_2.loc[new_table_2.index != 'Cluster percentage of drivers'] >= 75).astype(int)\n",
    "        new_table_3.loc['number of significant variables'] = new_table_3.sum()\n",
    "        #new_table_2.to_excel(f'table_{n_clusters}_clusters_pas3.xlsx', index=True)\n",
    "        #print(new_table_3)  \n",
    "        new_table_3.loc['Cluster significance'] = new_table_3 .loc['number of significant variables'] / 5\n",
    "        new_table_3.loc['Cluster significant?'] = new_table_3 .loc['Cluster significance']>=0.5\n",
    "        new_table_4=new_table_3\n",
    "        new_table_4.loc['Cluster percentage of drivers'] = table.loc['Cluster percentage of drivers']\n",
    "        new_table_4.loc['Significant clusters'] = np.nan\n",
    "    # Add a column with the percentage of significant cluster\n",
    "        new_table_4.loc['Significant clusters' ,'percentage of significant cluster'] = new_table_4.loc['Cluster significant?'].sum() / n_clusters\n",
    "    # Transpose the dataframe back to its original orientation\n",
    "    # Print the resulting dataframe\n",
    "        new_table_4.to_excel(f'table_{n_clusters}_clusters_{\"\".join(selected_columns)}.xlsx', index=True)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b19994410bcd7bd4741b4abc27d4585bc9fcc2a76957ee21de3842df5f71cb30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
